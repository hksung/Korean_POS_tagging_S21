{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Korean_POS_tagging_ver.1_token.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60EWtX8JFxC"
      },
      "source": [
        "**[Step 1]** Upload the file(\"ko_kaist-du-train.conllu.txt\") and read it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndc9HHnrFTTv",
        "outputId": "3a6a3586-a355-4098-a3f5-ad18b33d16ae"
      },
      "source": [
        "f = open('ko_kaist-ud-train.conllu.txt', 'r', encoding='utf-8') # encoding='utf-8' : Korean data set\n",
        "\n",
        "f_lines = f.readlines() #read by lines\n",
        "f.close()\n",
        "\n",
        "len(f_lines) #365476\n",
        "f_lines[:10] #sample_test_lines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# sent_id = M2TA_064-s1\\n',\n",
              " '# text = 하기야 짐승도 잘 가르치기만 하면 어느 정도는 순치될 수 있다.\\n',\n",
              " '1\\t하기야\\t하기야\\tCCONJ\\tmaj\\t_\\t8\\tcc\\t_\\t_\\n',\n",
              " '2\\t짐승도\\t짐승+도\\tADV\\tncn+jxc\\t_\\t8\\tadvcl\\t_\\t_\\n',\n",
              " '3\\t잘\\t잘\\tADV\\tmag\\t_\\t4\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t가르치기만\\t가르치+기+만\\tADV\\tpvg+etn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t하면\\t하+면\\tSCONJ\\tpvg+ecs\\t_\\t8\\tccomp\\t_\\t_\\n',\n",
              " '6\\t어느\\t어느\\tDET\\tmmd\\t_\\t7\\tdet\\t_\\t_\\n',\n",
              " '7\\t정도는\\t정도+는\\tNOUN\\tncn+jxt\\t_\\t8\\tdislocated\\t_\\t_\\n',\n",
              " '8\\t순치될\\t순치+되+ㄹ\\tVERB\\tncpa+xsv+etm\\t_\\t0\\troot\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzeOquW89sg0",
        "outputId": "fd2131b9-6126-49f5-b673-7fe353570908"
      },
      "source": [
        "f_lines[25:35] #check that some datas '\\n' and '# sent (or text)...' have to be deleted"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10\\t.\\t.\\tPUNCT\\tsf\\t_\\t9\\tpunct\\t_\\t_\\n',\n",
              " '\\n',\n",
              " '# sent_id = M2TA_064-s3\\n',\n",
              " '# text = 뭇 짐승들은 일단 배만 부르면 더 이상의 탐욕을 부리지 않는다.\\n',\n",
              " '1\\t뭇\\t뭇\\tADJ\\tmma\\t_\\t2\\tamod\\t_\\t_\\n',\n",
              " '2\\t짐승들은\\t짐승+들+은\\tNOUN\\tncn+xsn+jxt\\t_\\t9\\tdislocated\\t_\\t_\\n',\n",
              " '3\\t일단\\t일단\\tADV\\tmag\\t_\\t5\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t배만\\t배+만\\tADV\\tncn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t부르면\\t부르+면\\tSCONJ\\tpaa+ecs\\t_\\t9\\txcomp\\t_\\t_\\n',\n",
              " '6\\t더\\t더\\tADV\\tmag\\t_\\t7\\tadvmod\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pym53fcI4CPd"
      },
      "source": [
        "index = []\n",
        "word = []\n",
        "pos = []\n",
        "\n",
        "for i, line in enumerate(f_lines):\n",
        "    line = line.strip() # delete '\\n'\n",
        "    splits = line.split('\\t') # split by '\\t'\n",
        "\n",
        "    if len(splits) > 2: # filter '\\n\\'\n",
        "        try:\n",
        "            idx = int(splits[0]) # filter 'data starting with '#'\n",
        "            index.append(idx)\n",
        "            word.append(splits[1])\n",
        "            pos.append(splits[3])\n",
        "\n",
        "        except:\n",
        "            print(i, index[-5:], word[-5:], pos[-5:])\n",
        "            print(line) #check if there is an error in idx\n",
        "            # or use print(set(index))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2QJ145p73r2",
        "outputId": "6055266e-62e6-478e-ce6e-1675a78c4d8a"
      },
      "source": [
        "print(index[:20])\n",
        "print(word[:20])\n",
        "print(pos[:20])\n",
        "\n",
        "#check\n",
        "len(index) #296446\n",
        "len(word) #296446\n",
        "len(pos) #296446\n",
        "print(set(index))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "['하기야', '짐승도', '잘', '가르치기만', '하면', '어느', '정도는', '순치될', '수', '있다', '.', '사람이', '스스로', '만물의', '영장이라', '하고', '우쭐대는', '까닭이', '여기에', '있다']\n",
            "['CCONJ', 'ADV', 'ADV', 'ADV', 'SCONJ', 'DET', 'NOUN', 'VERB', 'NOUN', 'ADJ', 'PUNCT', 'NOUN', 'ADV', 'NOUN', 'SCONJ', 'SCONJ', 'VERB', 'NOUN', 'ADV', 'ADJ']\n",
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMl9KG4rKI2s",
        "outputId": "93d8bf1f-c5a8-4e97-c618-f79896faee94"
      },
      "source": [
        "len(index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piLQQn3yJccY"
      },
      "source": [
        "**[Step 2]** Format the data\n",
        "1. Represent the data as a list of dictionaries\n",
        "2. Represent words as dictionaries with multiple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWablQWF88-e"
      },
      "source": [
        "input_data = [] #total test sentences\n",
        "\n",
        "sent = [] #iterate through sentence\n",
        "i = 0\n",
        "pos_index = 0\n",
        "\n",
        "while (i < len(index)):\n",
        "    if (int(index[i])) == pos_index + 1:\n",
        "          sent.append({\"word\" :word[i], \"pos\" :pos[i]})\n",
        "          pos_index += 1\n",
        "          i = i +1\n",
        "    else:\n",
        "        if sent:\n",
        "            input_data.append(sent) #to filterout empty index\n",
        "        else:\n",
        "            i = i +1\n",
        "        pos_index = 0 #new sentence, make the number of sentence to default number\n",
        "        sent = []\n",
        "        if i == (len(index)-1):\n",
        "            break\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print (i, len(index)) #check if there is no infinite loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmyF4hEA4JA",
        "outputId": "16d60a92-a7a5-4c47-82e1-a44857907a3b"
      },
      "source": [
        "len(input_data) #23009 (the number of total sentences, average 12.8 words for a sentence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQXCPh0A_fF",
        "outputId": "906fc8db-5138-4e82-e6fb-8f7034c6f854"
      },
      "source": [
        "print (input_data[1][:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'word': '사람이', 'pos': 'NOUN'}, {'word': '스스로', 'pos': 'ADV'}, {'word': '만물의', 'pos': 'NOUN'}, {'word': '영장이라', 'pos': 'SCONJ'}, {'word': '하고', 'pos': 'SCONJ'}, {'word': '우쭐대는', 'pos': 'VERB'}, {'word': '까닭이', 'pos': 'NOUN'}, {'word': '여기에', 'pos': 'ADV'}, {'word': '있다', 'pos': 'ADJ'}, {'word': '.', 'pos': 'PUNCT'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybzN8QNKqXa"
      },
      "source": [
        "**[Step 3]** Check frequency dict (Optional, just for fun)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXm0VFP3L2Mj",
        "outputId": "afad2ffa-d6b0-4007-b5d2-c8de93f9a956"
      },
      "source": [
        "def freq_add(item, d):\n",
        "    if item not in d:\n",
        "        d[item] = 1\n",
        "    else:\n",
        "        d[item] += 1\n",
        "\n",
        "# iterate through sentences, get tabulate tags for each word\n",
        "def tag_freq(data_set):\n",
        "    freq = {}\n",
        "    for sent in data_set:\n",
        "        for item in sent:\n",
        "            if item[\"word\"] not in freq:\n",
        "                freq[item[\"word\"]] = {}\n",
        "            freq_add(item[\"pos\"], freq[item[\"word\"]])\n",
        "\n",
        "    return (freq)\n",
        "\n",
        "#create frequency dic\n",
        "word_tags = tag_freq(input_data)\n",
        "\n",
        "#check\n",
        "print(word_tags[\"사람\"]) #'human' in Korean\n",
        "print(word_tags[\"사랑\"]) #'love' in Korean\n",
        "print(word_tags[\"가\"]) #ambiguous without context, 'go', 'aux' for sub\n",
        "print(word_tags[\"나는\"]) #ambiguous without context, mostly 'I' but sometime 'fly'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NOUN': 38}\n",
            "{'NOUN': 4}\n",
            "{'ADP': 68, 'SCONJ': 2, 'PROPN': 1, 'VERB': 1, 'AUX': 1}\n",
            "{'VERB': 22, 'PRON': 264}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeyp7AVWiLk"
      },
      "source": [
        "**[Step 4]** Format the data for scikit-learn and extract features\n",
        "1. Add some features\n",
        "2. Flat the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMnd1DkuXOba"
      },
      "source": [
        "def simple_features(input_sent, idx, token):\n",
        "\n",
        "  features = {}\n",
        "  features[\"word\"] = token[\"word\"]\n",
        "  #features[\"pos\"] = token[\"pos\"]\n",
        "\n",
        "  if idx == 0:\n",
        "      features[\"prev_pos\"] = \"<start>\"\n",
        "      features[\"prev_prev_pos\"] = \"<start>_<start>\"\n",
        "\n",
        "  elif idx == 1:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = \"<start>_\"+ input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_word\"] = input_sent[idx-1][\"word\"]\n",
        "\n",
        "  else:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = input_sent[idx-2][\"pos\"]\n",
        "\n",
        "  features[\"suffix_tg\"] = token[\"word\"][-1:]\n",
        "\n",
        "  return (features)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpFsobMIcSne"
      },
      "source": [
        "def feature_extractor(input_data): \n",
        "\tfeature_list = [] \n",
        "\tfor sent in input_data: \n",
        "\t\tfor idx, token in enumerate(sent): \n",
        "\t\t\tfeature_list.append(simple_features(sent,idx,token)) \n",
        "\treturn(feature_list)\n",
        "\n",
        "def extract_pos(input_data):\n",
        "\tpos_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tpos_list.append(token[\"pos\"])\n",
        "\treturn(pos_list)\n",
        "\n",
        "def extract_words(input_data):\n",
        "\tword_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tword_list.append(token[\"word\"])\n",
        "\treturn(word_list)\n",
        "\n",
        "flat_words = extract_words(input_data)\n",
        "flat_pos = extract_pos(input_data)\n",
        "flat_features = feature_extractor(input_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoodUaGMdRo0",
        "outputId": "db8fe0e9-3e95-45aa-dd00-63ed1dad3e3f"
      },
      "source": [
        "for idx, x in enumerate(flat_words[:20]):\n",
        "  print(x, flat_pos[idx], flat_features[idx])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "하기야 CCONJ {'word': '하기야', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '야'}\n",
            "짐승도 ADV {'word': '짐승도', 'prev_pos': 'CCONJ', 'prev_prev_pos': '<start>_CCONJ', 'prev_word': '하기야', 'suffix_tg': '도'}\n",
            "잘 ADV {'word': '잘', 'prev_pos': 'ADV', 'prev_prev_pos': 'CCONJ', 'suffix_tg': '잘'}\n",
            "가르치기만 ADV {'word': '가르치기만', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '만'}\n",
            "하면 SCONJ {'word': '하면', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '면'}\n",
            "어느 DET {'word': '어느', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'ADV', 'suffix_tg': '느'}\n",
            "정도는 NOUN {'word': '정도는', 'prev_pos': 'DET', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '는'}\n",
            "순치될 VERB {'word': '순치될', 'prev_pos': 'NOUN', 'prev_prev_pos': 'DET', 'suffix_tg': '될'}\n",
            "수 NOUN {'word': '수', 'prev_pos': 'VERB', 'prev_prev_pos': 'NOUN', 'suffix_tg': '수'}\n",
            "있다 ADJ {'word': '있다', 'prev_pos': 'NOUN', 'prev_prev_pos': 'VERB', 'suffix_tg': '다'}\n",
            ". PUNCT {'word': '.', 'prev_pos': 'ADJ', 'prev_prev_pos': 'NOUN', 'suffix_tg': '.'}\n",
            "사람이 NOUN {'word': '사람이', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '이'}\n",
            "스스로 ADV {'word': '스스로', 'prev_pos': 'NOUN', 'prev_prev_pos': '<start>_NOUN', 'prev_word': '사람이', 'suffix_tg': '로'}\n",
            "만물의 NOUN {'word': '만물의', 'prev_pos': 'ADV', 'prev_prev_pos': 'NOUN', 'suffix_tg': '의'}\n",
            "영장이라 SCONJ {'word': '영장이라', 'prev_pos': 'NOUN', 'prev_prev_pos': 'ADV', 'suffix_tg': '라'}\n",
            "하고 SCONJ {'word': '하고', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'NOUN', 'suffix_tg': '고'}\n",
            "우쭐대는 VERB {'word': '우쭐대는', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '는'}\n",
            "까닭이 NOUN {'word': '까닭이', 'prev_pos': 'VERB', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '이'}\n",
            "여기에 ADV {'word': '여기에', 'prev_pos': 'NOUN', 'prev_prev_pos': 'VERB', 'suffix_tg': '에'}\n",
            "있다 ADJ {'word': '있다', 'prev_pos': 'ADV', 'prev_prev_pos': 'NOUN', 'suffix_tg': '다'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kol12yF1LMNo",
        "outputId": "cc969a84-2cea-44ac-e62e-e36539589411"
      },
      "source": [
        "# Training and test sets\n",
        "\n",
        "print(len(flat_words)*.67) #198602\n",
        "\n",
        "#training data\n",
        "train_words = flat_words[:198602]\n",
        "train_pos = flat_pos[:198602]\n",
        "train_features = flat_features[:198602]\n",
        "\n",
        "#test data\n",
        "test_words = flat_words[198602:]\n",
        "test_pos = flat_pos[198602:]\n",
        "test_features = flat_features[198602:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198602.74000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmQ8jhnihyJ"
      },
      "source": [
        "**[Step 5]** Use scikit-learn for POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbxkJxZjEdr",
        "outputId": "ec048a88-1745-49fd-e9a2-f6bf5e0761e3"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse = True)\n",
        "\n",
        "train_features_vec = vec.fit_transform(train_features) #.fit: train\n",
        "\n",
        "test_features_vec = vec.transform(test_features)\n",
        "\n",
        "def pos_cats(pos_list):\n",
        "\tcat_d = {}\n",
        "\tfor idx, x in enumerate(list(set(pos_list))):\n",
        "\t\tcat_d[x] = idx\n",
        "\treturn(cat_d)\n",
        "\n",
        "def convert_pos(pos_list,pos_d):\n",
        "\tconverted = []\n",
        "\tfor x in pos_list:\n",
        "\t\tconverted.append(pos_d[x])\n",
        "\treturn(converted)\n",
        "\n",
        "def extract_pred_pos(pred_array,rev_d):\n",
        "  predicted = []\n",
        "  for x in pred_array:\n",
        "    predicted.append(rev_d[x])\n",
        "  return (predicted)\n",
        "\n",
        "pos_d = pos_cats(flat_pos) #create pos to number dictionary\n",
        "rev_pos_d = {value: key for (key, value) in pos_d.items()} #create number to POS dictionary for decoding output\n",
        "train_pos_num = convert_pos(train_pos,pos_d) #convert training pos tags to numbers\n",
        "\n",
        "print(pos_d)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'INTJ': 0, 'CCONJ': 1, 'PUNCT': 2, 'AUX': 3, 'SYM': 4, 'ADV': 5, 'PROPN': 6, 'NOUN': 7, 'VERB': 8, 'NUM': 9, 'X': 10, 'ADJ': 11, 'PRON': 12, 'ADP': 13, 'SCONJ': 14, 'PART': 15, 'DET': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA969t63jZdr",
        "outputId": "4536fd02-5329-4ed6-8179-eabecd27449f"
      },
      "source": [
        "train_pos_num[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 5, 5, 5, 14, 16, 7, 8, 7, 11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8kkO9gRjeBk"
      },
      "source": [
        "from sklearn import tree \n",
        "\n",
        "clf = tree.DecisionTreeClassifier() \n",
        "clf = clf.fit(train_features_vec,train_pos_num) \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbXKxOo5pIr"
      },
      "source": [
        "**[Step 6]** Simple and Refined Accuracy\n",
        "\n",
        "With the model above, now we will\n",
        "\n",
        "(1) test its overall accuracy\n",
        "(2) its by-tag accuracy\n",
        "(3) try some test sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHZLOVkjrBx"
      },
      "source": [
        "# accuracy\n",
        "def pred_accuracy(pred,gold):\n",
        "\tc = 0\n",
        "\tf = 0\n",
        "\n",
        "\tfor idx, x in enumerate(pred):\n",
        "\t\t#print(x,gold[idx][\"pos\"])\n",
        "\t\tif x == gold[idx]:\n",
        "\t\t\tc+=1\n",
        "\t\telse:\n",
        "\t\t\tf+=1\n",
        "\treturn(c/(c+f))\n",
        "\n",
        "def prec_rec(accuracy_dict):\n",
        "\taccuracy_dict[\"TC\"] = accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"]\n",
        "\tif accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"] == 0:\n",
        "\t\taccuracy_dict[\"recall\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"recall\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"])\n",
        "\n",
        "\tif accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"] == 0:\n",
        "\t\taccuracy_dict[\"precision\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"precision\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"])\n",
        "\tif accuracy_dict[\"precision\"] == 0 and accuracy_dict[\"recall\"] == 0:\n",
        "\t\taccuracy_dict[\"f1\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"f1\"] = 2 * ((accuracy_dict[\"precision\"] * accuracy_dict[\"recall\"])/(accuracy_dict[\"precision\"] + accuracy_dict[\"recall\"]))\n",
        "\n",
        "\n",
        "def tag_prec_rec_flat(tested,gold):\n",
        "\ttag_d = {}\n",
        "\n",
        "\tfor idx, item in enumerate(gold):\n",
        "\t\t### convert formats, as needed: ###\n",
        "\t\tif type(item) == str:\n",
        "\t\t\titem = {\"pos\" : item}\n",
        "\n",
        "\t\tif type(tested[idx]) == str:\n",
        "\t\t\ttested[idx] = {\"pos\" : tested[idx]}\n",
        "\n",
        "\t\t### update tag dictionary as needed ###\n",
        "\t\tif item[\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[item[\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\t\tif tested[idx][\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\n",
        "\t\t### tabulate accuracy ###\n",
        "\t\tif item[\"pos\"] == tested[idx][\"pos\"]:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"TP\"] += 1\n",
        "\t\telse:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"FN\"] += 1\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]][\"FP\"] += 1\n",
        "\n",
        "\tfor x in tag_d:\n",
        "\t\tprec_rec(tag_d[x])\n",
        "\n",
        "\treturn(tag_d)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M35j0naZjmVc",
        "outputId": "e0c3ae83-8a75-46ba-d49d-e410411c9a14"
      },
      "source": [
        "clf_pred = clf.predict(test_features_vec)\n",
        "# process train data and convert it from numbers to POS tags\n",
        "clf_pred_pos = extract_pred_pos(clf_pred, rev_pos_d)\n",
        "clf_pred_pos[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'VERB', 'ADV', 'PUNCT', 'VERB', 'NOUN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMpbCqIxAGQa",
        "outputId": "19f8206f-fa92-49d3-d2de-3e723c08f1f0"
      },
      "source": [
        "# check simple accuracy\n",
        "pred_accuracy(clf_pred_pos,test_pos) #0.87 which is better than 0.80(suffix_tg was token(\"words\"[-2:]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8726436311592721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0N_2n7oAL_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3806ebbb-a94f-4e52-8f7d-ae69cdcc35ab"
      },
      "source": [
        "# check by-tag accuracy \n",
        "\n",
        "pred_by_tag_accuracy = tag_prec_rec_flat(clf_pred_pos, test_pos)\n",
        "print(pred_by_tag_accuracy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ADJ': {'TP': 3436, 'FP': 309, 'FN': 630, 'TC': 4066, 'recall': 0.8450565666502705, 'precision': 0.9174899866488652, 'f1': 0.8797849187043911}, 'NOUN': {'TP': 27041, 'FP': 4673, 'FN': 1742, 'TC': 28783, 'recall': 0.9394781641941424, 'precision': 0.8526518256921234, 'f1': 0.8939616840504487}, 'VERB': {'TP': 13838, 'FP': 3037, 'FN': 2704, 'TC': 16542, 'recall': 0.8365372989964938, 'precision': 0.8200296296296297, 'f1': 0.8282012149504744}, 'ADV': {'TP': 12744, 'FP': 1112, 'FN': 896, 'TC': 13640, 'recall': 0.9343108504398827, 'precision': 0.9197459584295612, 'f1': 0.9269711958102997}, 'PUNCT': {'TP': 10624, 'FP': 0, 'FN': 31, 'TC': 10655, 'recall': 0.9970905678085406, 'precision': 1.0, 'f1': 0.9985431646223976}, 'AUX': {'TP': 2777, 'FP': 419, 'FN': 761, 'TC': 3538, 'recall': 0.7849067269643867, 'precision': 0.8688986232790988, 'f1': 0.8247698247698247}, 'CCONJ': {'TP': 5029, 'FP': 1227, 'FN': 480, 'TC': 5509, 'recall': 0.9128698493374479, 'precision': 0.8038682864450127, 'f1': 0.8549086272843178}, 'PRON': {'TP': 1918, 'FP': 96, 'FN': 276, 'TC': 2194, 'recall': 0.8742023701002735, 'precision': 0.9523336643495531, 'f1': 0.911596958174905}, 'DET': {'TP': 1402, 'FP': 197, 'FN': 110, 'TC': 1512, 'recall': 0.9272486772486772, 'precision': 0.8767979987492183, 'f1': 0.9013179042108647}, 'SCONJ': {'TP': 3701, 'FP': 850, 'FN': 1271, 'TC': 4972, 'recall': 0.7443684633950121, 'precision': 0.8132278620083498, 'f1': 0.7772760684658196}, 'NUM': {'TP': 1231, 'FP': 153, 'FN': 285, 'TC': 1516, 'recall': 0.8120052770448549, 'precision': 0.8894508670520231, 'f1': 0.8489655172413794}, 'PROPN': {'TP': 987, 'FP': 318, 'FN': 3042, 'TC': 4029, 'recall': 0.24497393894266567, 'precision': 0.7563218390804598, 'f1': 0.37007874015748027}, 'ADP': {'TP': 443, 'FP': 18, 'FN': 37, 'TC': 480, 'recall': 0.9229166666666667, 'precision': 0.9609544468546638, 'f1': 0.9415515409139213}, 'X': {'TP': 159, 'FP': 35, 'FN': 123, 'TC': 282, 'recall': 0.5638297872340425, 'precision': 0.8195876288659794, 'f1': 0.6680672268907563}, 'PART': {'TP': 8, 'FP': 7, 'FN': 58, 'TC': 66, 'recall': 0.12121212121212122, 'precision': 0.5333333333333333, 'f1': 0.19753086419753085}, 'SYM': {'TP': 24, 'FP': 0, 'FN': 9, 'TC': 33, 'recall': 0.7272727272727273, 'precision': 1.0, 'f1': 0.8421052631578948}, 'INTJ': {'TP': 0, 'FP': 7, 'FN': 3, 'TC': 3, 'recall': 0.0, 'precision': 0.0, 'f1': 0}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fg7uTUAtuo",
        "outputId": "5bcc4d78-388f-4af3-d1fd-41c124e4f1dd"
      },
      "source": [
        "#sort data by frequency (\"TC\")\n",
        "from operator import *\n",
        "pred_by_tag_accuracy_sorted = sorted(pred_by_tag_accuracy.items(),key=lambda x:getitem(x[1],'TC'), reverse = True)\n",
        "\n",
        "#output F1 score of top ten most frequent tags\n",
        "for x in pred_by_tag_accuracy_sorted[:10]:\n",
        "\tprint(x[0], x[1][\"f1\"])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOUN 0.8939616840504487\n",
            "VERB 0.8282012149504744\n",
            "ADV 0.9269711958102997\n",
            "PUNCT 0.9985431646223976\n",
            "CCONJ 0.8549086272843178\n",
            "SCONJ 0.7772760684658196\n",
            "ADJ 0.8797849187043911\n",
            "PROPN 0.37007874015748027\n",
            "AUX 0.8247698247698247\n",
            "PRON 0.911596958174905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVL8T_VNDVOn"
      },
      "source": [
        "''' \n",
        "Try a few test cases to see how our tagger does on particular words in particular contexts\n",
        "'''\n",
        "\n",
        "def tagger(model,vec,rev_dict,extractor,token_list):\n",
        "\ttagged = [] #for final word + tag output\n",
        "\n",
        "\tfor sent in token_list:\n",
        "\t\tfeatures = [] #in progress tagging list\n",
        "\t\ttagging = [] #final word-tag pairs\n",
        "\n",
        "\t\tfor idx, token in enumerate(sent):\n",
        "\t\t\tfeatures.append({\"word\" : token}) # add word to feature set\n",
        "\t\t\t#print(features,idx,features[idx])\n",
        "\t\t\tfeatures[idx] = extractor(features,idx,features[idx]) #add featured token to features list\n",
        "\t\t\t#print(features)\n",
        "\t\t\t#print(vec.transform(features[idx]))\n",
        "\t\t\t#print(model.predict(vec.transform([features[idx]])))\n",
        "\t\t\tfeatures[idx][\"pos\"] = rev_dict[model.predict(vec.transform([features[idx]]))[0]] #add pos to features - this happens one token at a time\n",
        "\t\t\ttagging.append({\"word\" : token, \"pos\" : features[idx][\"pos\"]}) #add word-tag pairs to sentence level output\n",
        "\t\ttagged.append(tagging) #add sentence to output\n",
        "\n",
        "\treturn(tagged)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xR7Ed65EmZN",
        "outputId": "54f865ef-2cc5-405e-d395-23eb5bae9a67"
      },
      "source": [
        "sample1 = [\"후반작업을 이유로 불참 예정이던 김원석 감독은 제작발표회장에 깜짝 등장해 \"\"\"\"기대는 낮추시고 응원하는 마음으로 봐달라\"\"\"\"고 당부했다.\".split(\" \")]\n",
        "final1 = tagger(clf, vec, rev_pos_d, simple_features, sample1)\n",
        "\n",
        "for i in final1:\n",
        "  for j in i:\n",
        "    print(j, sep='\\n')\n",
        "  print()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': '후반작업을', 'pos': 'NOUN'}\n",
            "{'word': '이유로', 'pos': 'ADV'}\n",
            "{'word': '불참', 'pos': 'ADV'}\n",
            "{'word': '예정이던', 'pos': 'VERB'}\n",
            "{'word': '김원석', 'pos': 'NOUN'}\n",
            "{'word': '감독은', 'pos': 'NOUN'}\n",
            "{'word': '제작발표회장에', 'pos': 'ADV'}\n",
            "{'word': '깜짝', 'pos': 'ADV'}\n",
            "{'word': '등장해', 'pos': 'VERB'}\n",
            "{'word': '기대는', 'pos': 'NOUN'}\n",
            "{'word': '낮추시고', 'pos': 'CCONJ'}\n",
            "{'word': '응원하는', 'pos': 'VERB'}\n",
            "{'word': '마음으로', 'pos': 'ADV'}\n",
            "{'word': '봐달라고', 'pos': 'VERB'}\n",
            "{'word': '당부했다.', 'pos': 'NOUN'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxJxw3-Z_pwy",
        "outputId": "b750ca00-8a95-45ea-f663-ead41b671df5"
      },
      "source": [
        "sample2 = [\"세종은 조선의 네 번째 국왕이며 그의 업적에 대한 존경의 의미를 담은 명칭인 세종대왕으로 자주 일컬어진다.\".split(\" \")]\n",
        "final2 = tagger(clf, vec, rev_pos_d, simple_features, sample2)\n",
        "\n",
        "for i in final2:\n",
        "  for j in i:\n",
        "    print(j, sep='\\n')\n",
        "  print()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': '세종은', 'pos': 'PROPN'}\n",
            "{'word': '조선의', 'pos': 'PROPN'}\n",
            "{'word': '네', 'pos': 'PROPN'}\n",
            "{'word': '번째', 'pos': 'PROPN'}\n",
            "{'word': '국왕이며', 'pos': 'PROPN'}\n",
            "{'word': '그의', 'pos': 'PRON'}\n",
            "{'word': '업적에', 'pos': 'ADV'}\n",
            "{'word': '대한', 'pos': 'VERB'}\n",
            "{'word': '존경의', 'pos': 'NOUN'}\n",
            "{'word': '의미를', 'pos': 'NOUN'}\n",
            "{'word': '담은', 'pos': 'VERB'}\n",
            "{'word': '명칭인', 'pos': 'VERB'}\n",
            "{'word': '세종대왕으로', 'pos': 'ADV'}\n",
            "{'word': '자주', 'pos': 'ADV'}\n",
            "{'word': '일컬어진다.', 'pos': 'NOUN'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}