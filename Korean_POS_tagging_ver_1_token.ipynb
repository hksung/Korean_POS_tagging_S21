{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Korean_POS_tagging_ver.1_token.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60EWtX8JFxC"
      },
      "source": [
        "**[Step 1]** Upload the file(\"ko_kaist-du-train.conllu.txt\") and read it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndc9HHnrFTTv",
        "outputId": "a9fc0b5e-4e76-4d16-c30f-cf7cc3685ace"
      },
      "source": [
        "f = open('ko_kaist-ud-train.conllu.txt', 'r', encoding='utf-8') # encoding='utf-8' : Korean data set\n",
        "\n",
        "f_lines = f.readlines() #read by lines\n",
        "f.close()\n",
        "\n",
        "len(f_lines) #365476\n",
        "f_lines[:10] #sample_test_lines"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# sent_id = M2TA_064-s1\\n',\n",
              " '# text = 하기야 짐승도 잘 가르치기만 하면 어느 정도는 순치될 수 있다.\\n',\n",
              " '1\\t하기야\\t하기야\\tCCONJ\\tmaj\\t_\\t8\\tcc\\t_\\t_\\n',\n",
              " '2\\t짐승도\\t짐승+도\\tADV\\tncn+jxc\\t_\\t8\\tadvcl\\t_\\t_\\n',\n",
              " '3\\t잘\\t잘\\tADV\\tmag\\t_\\t4\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t가르치기만\\t가르치+기+만\\tADV\\tpvg+etn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t하면\\t하+면\\tSCONJ\\tpvg+ecs\\t_\\t8\\tccomp\\t_\\t_\\n',\n",
              " '6\\t어느\\t어느\\tDET\\tmmd\\t_\\t7\\tdet\\t_\\t_\\n',\n",
              " '7\\t정도는\\t정도+는\\tNOUN\\tncn+jxt\\t_\\t8\\tdislocated\\t_\\t_\\n',\n",
              " '8\\t순치될\\t순치+되+ㄹ\\tVERB\\tncpa+xsv+etm\\t_\\t0\\troot\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzeOquW89sg0",
        "outputId": "5f7f1cb5-bb19-48db-c9ef-4319450ab911"
      },
      "source": [
        "f_lines[25:35] #check that some datas '\\n' and '# sent (or text)...' have to be deleted"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10\\t.\\t.\\tPUNCT\\tsf\\t_\\t9\\tpunct\\t_\\t_\\n',\n",
              " '\\n',\n",
              " '# sent_id = M2TA_064-s3\\n',\n",
              " '# text = 뭇 짐승들은 일단 배만 부르면 더 이상의 탐욕을 부리지 않는다.\\n',\n",
              " '1\\t뭇\\t뭇\\tADJ\\tmma\\t_\\t2\\tamod\\t_\\t_\\n',\n",
              " '2\\t짐승들은\\t짐승+들+은\\tNOUN\\tncn+xsn+jxt\\t_\\t9\\tdislocated\\t_\\t_\\n',\n",
              " '3\\t일단\\t일단\\tADV\\tmag\\t_\\t5\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t배만\\t배+만\\tADV\\tncn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t부르면\\t부르+면\\tSCONJ\\tpaa+ecs\\t_\\t9\\txcomp\\t_\\t_\\n',\n",
              " '6\\t더\\t더\\tADV\\tmag\\t_\\t7\\tadvmod\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pym53fcI4CPd"
      },
      "source": [
        "index = []\n",
        "word = []\n",
        "pos = []\n",
        "\n",
        "for i, line in enumerate(f_lines):\n",
        "    line = line.strip() # delete '\\n'\n",
        "    splits = line.split('\\t') # split by '\\t'\n",
        "\n",
        "    if len(splits) > 2: # filter '\\n\\'\n",
        "        try:\n",
        "            idx = int(splits[0]) # filter 'data starting with '#'\n",
        "            index.append(idx)\n",
        "            word.append(splits[1])\n",
        "            pos.append(splits[3])\n",
        "\n",
        "        except:\n",
        "            print(i, index[-5:], word[-5:], pos[-5:])\n",
        "            print(line) #check if there is an error in idx\n",
        "            # or use print(set(index))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2QJ145p73r2",
        "outputId": "26105af9-9f7a-4a6b-eca9-925462ea89de"
      },
      "source": [
        "print(index[:20])\n",
        "print(word[:20])\n",
        "print(pos[:20])\n",
        "\n",
        "#check\n",
        "len(index) #296446\n",
        "len(word) #296446\n",
        "len(pos) #296446\n",
        "print(set(index))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "['하기야', '짐승도', '잘', '가르치기만', '하면', '어느', '정도는', '순치될', '수', '있다', '.', '사람이', '스스로', '만물의', '영장이라', '하고', '우쭐대는', '까닭이', '여기에', '있다']\n",
            "['CCONJ', 'ADV', 'ADV', 'ADV', 'SCONJ', 'DET', 'NOUN', 'VERB', 'NOUN', 'ADJ', 'PUNCT', 'NOUN', 'ADV', 'NOUN', 'SCONJ', 'SCONJ', 'VERB', 'NOUN', 'ADV', 'ADJ']\n",
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMl9KG4rKI2s",
        "outputId": "1a8dd1c8-1fc5-49ff-8e63-3799b604c206"
      },
      "source": [
        "len(index)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piLQQn3yJccY"
      },
      "source": [
        "**[Step 2]** Format the data\n",
        "1. Represent the data as a list of dictionaries\n",
        "2. Represent words as dictionaries with multiple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWablQWF88-e"
      },
      "source": [
        "input_data = [] #total test sentences\n",
        "\n",
        "sent = [] #iterate through sentence\n",
        "i = 0\n",
        "pos_index = 0\n",
        "\n",
        "while (i < len(index)):\n",
        "    if (int(index[i])) == pos_index + 1:\n",
        "          sent.append({\"word\" :word[i], \"pos\" :pos[i]})\n",
        "          pos_index += 1\n",
        "          i = i +1\n",
        "    else:\n",
        "        if sent:\n",
        "            input_data.append(sent) #to filterout empty index\n",
        "        else:\n",
        "            i = i +1\n",
        "        pos_index = 0 #new sentence, make the number of sentence to default number\n",
        "        sent = []\n",
        "        if i == (len(index)-1):\n",
        "            break\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print (i, len(index)) #check if there is no infinite loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmyF4hEA4JA",
        "outputId": "bd85af3e-2d1c-4c38-962a-db1406cac3c7"
      },
      "source": [
        "len(input_data) #23009 (the number of total sentences, average 12.8 words for a sentence)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQXCPh0A_fF",
        "outputId": "c0acb0c4-2699-48b0-b59d-ba254acb17a1"
      },
      "source": [
        "print (input_data[1][:10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'word': '사람이', 'pos': 'NOUN'}, {'word': '스스로', 'pos': 'ADV'}, {'word': '만물의', 'pos': 'NOUN'}, {'word': '영장이라', 'pos': 'SCONJ'}, {'word': '하고', 'pos': 'SCONJ'}, {'word': '우쭐대는', 'pos': 'VERB'}, {'word': '까닭이', 'pos': 'NOUN'}, {'word': '여기에', 'pos': 'ADV'}, {'word': '있다', 'pos': 'ADJ'}, {'word': '.', 'pos': 'PUNCT'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybzN8QNKqXa"
      },
      "source": [
        "**[Step 3]** Check frequency dict (Optional, just for fun)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXm0VFP3L2Mj",
        "outputId": "e78ea9a5-49b4-4a72-a9d3-84fd9118b734"
      },
      "source": [
        "def freq_add(item, d):\n",
        "    if item not in d:\n",
        "        d[item] = 1\n",
        "    else:\n",
        "        d[item] += 1\n",
        "\n",
        "# iterate through sentences, get tabulate tags for each word\n",
        "def tag_freq(data_set):\n",
        "    freq = {}\n",
        "    for sent in data_set:\n",
        "        for item in sent:\n",
        "            if item[\"word\"] not in freq:\n",
        "                freq[item[\"word\"]] = {}\n",
        "            freq_add(item[\"pos\"], freq[item[\"word\"]])\n",
        "\n",
        "    return (freq)\n",
        "\n",
        "#create frequency dic\n",
        "word_tags = tag_freq(input_data)\n",
        "\n",
        "#check\n",
        "print(word_tags[\"사람\"]) #'human' in Korean\n",
        "print(word_tags[\"사랑\"]) #'love' in Korean\n",
        "print(word_tags[\"가\"]) #ambiguous without context, 'go', 'aux' for sub\n",
        "print(word_tags[\"나는\"]) #ambiguous without context, mostly 'I' but sometime 'fly'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NOUN': 38}\n",
            "{'NOUN': 4}\n",
            "{'ADP': 68, 'SCONJ': 2, 'PROPN': 1, 'VERB': 1, 'AUX': 1}\n",
            "{'VERB': 22, 'PRON': 264}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeyp7AVWiLk"
      },
      "source": [
        "**[Step 4]** Format the data for scikit-learn and extract features\n",
        "1. Add some features\n",
        "2. Flat the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMnd1DkuXOba"
      },
      "source": [
        "def simple_features(input_sent, idx, token):\n",
        "\n",
        "  features = {}\n",
        "  features[\"word\"] = token[\"word\"]\n",
        "  #features[\"pos\"] = token[\"pos\"]\n",
        "\n",
        "  if idx == 0:\n",
        "      features[\"prev_pos\"] = \"<start>\"\n",
        "      features[\"prev_prev_pos\"] = \"<start>_<start>\"\n",
        "\n",
        "  elif idx == 1:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = \"<start>_\"+ input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_word\"] = input_sent[idx-1][\"word\"]\n",
        "\n",
        "  else:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = input_sent[idx-2][\"pos\"]\n",
        "\n",
        "  features[\"suffix_tg\"] = token[\"word\"][-2:]\n",
        "\n",
        "  return (features)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpFsobMIcSne"
      },
      "source": [
        "def feature_extractor(input_data): \n",
        "\tfeature_list = [] \n",
        "\tfor sent in input_data: \n",
        "\t\tfor idx, token in enumerate(sent): \n",
        "\t\t\tfeature_list.append(simple_features(sent,idx,token)) \n",
        "\treturn(feature_list)\n",
        "\n",
        "def extract_pos(input_data):\n",
        "\tpos_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tpos_list.append(token[\"pos\"])\n",
        "\treturn(pos_list)\n",
        "\n",
        "def extract_words(input_data):\n",
        "\tword_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tword_list.append(token[\"word\"])\n",
        "\treturn(word_list)\n",
        "\n",
        "flat_words = extract_words(input_data)\n",
        "flat_pos = extract_pos(input_data)\n",
        "flat_features = feature_extractor(input_data)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoodUaGMdRo0",
        "outputId": "90d8aab4-0b6c-49cb-debd-869b5197b504"
      },
      "source": [
        "for idx, x in enumerate(flat_words[:20]):\n",
        "  print(x, flat_pos[idx], flat_features[idx])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "하기야 CCONJ {'word': '하기야', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '기야'}\n",
            "짐승도 ADV {'word': '짐승도', 'prev_pos': 'CCONJ', 'prev_prev_pos': '<start>_CCONJ', 'prev_word': '하기야', 'suffix_tg': '승도'}\n",
            "잘 ADV {'word': '잘', 'prev_pos': 'ADV', 'prev_prev_pos': 'CCONJ', 'suffix_tg': '잘'}\n",
            "가르치기만 ADV {'word': '가르치기만', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '기만'}\n",
            "하면 SCONJ {'word': '하면', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '하면'}\n",
            "어느 DET {'word': '어느', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'ADV', 'suffix_tg': '어느'}\n",
            "정도는 NOUN {'word': '정도는', 'prev_pos': 'DET', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '도는'}\n",
            "순치될 VERB {'word': '순치될', 'prev_pos': 'NOUN', 'prev_prev_pos': 'DET', 'suffix_tg': '치될'}\n",
            "수 NOUN {'word': '수', 'prev_pos': 'VERB', 'prev_prev_pos': 'NOUN', 'suffix_tg': '수'}\n",
            "있다 ADJ {'word': '있다', 'prev_pos': 'NOUN', 'prev_prev_pos': 'VERB', 'suffix_tg': '있다'}\n",
            ". PUNCT {'word': '.', 'prev_pos': 'ADJ', 'prev_prev_pos': 'NOUN', 'suffix_tg': '.'}\n",
            "사람이 NOUN {'word': '사람이', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '람이'}\n",
            "스스로 ADV {'word': '스스로', 'prev_pos': 'NOUN', 'prev_prev_pos': '<start>_NOUN', 'prev_word': '사람이', 'suffix_tg': '스로'}\n",
            "만물의 NOUN {'word': '만물의', 'prev_pos': 'ADV', 'prev_prev_pos': 'NOUN', 'suffix_tg': '물의'}\n",
            "영장이라 SCONJ {'word': '영장이라', 'prev_pos': 'NOUN', 'prev_prev_pos': 'ADV', 'suffix_tg': '이라'}\n",
            "하고 SCONJ {'word': '하고', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'NOUN', 'suffix_tg': '하고'}\n",
            "우쭐대는 VERB {'word': '우쭐대는', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '대는'}\n",
            "까닭이 NOUN {'word': '까닭이', 'prev_pos': 'VERB', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '닭이'}\n",
            "여기에 ADV {'word': '여기에', 'prev_pos': 'NOUN', 'prev_prev_pos': 'VERB', 'suffix_tg': '기에'}\n",
            "있다 ADJ {'word': '있다', 'prev_pos': 'ADV', 'prev_prev_pos': 'NOUN', 'suffix_tg': '있다'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kol12yF1LMNo",
        "outputId": "43574678-fb0d-4ba4-aff2-f4cc87c820d0"
      },
      "source": [
        "# Training and test sets\n",
        "\n",
        "print(len(flat_words)*.67) #198602\n",
        "\n",
        "#training data\n",
        "train_words = flat_words[:198602]\n",
        "train_pos = flat_pos[:198602]\n",
        "train_features = flat_features[:198602]\n",
        "\n",
        "#test data\n",
        "test_words = flat_words[198602:]\n",
        "test_pos = flat_pos[198602:]\n",
        "test_features = flat_features[198602:]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198602.74000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmQ8jhnihyJ"
      },
      "source": [
        "**[Step 5]** Use scikit-learn for POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbxkJxZjEdr",
        "outputId": "1ba5e47f-0926-46d4-dcb6-7a9ee98058c2"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse = True)\n",
        "\n",
        "train_features_vec = vec.fit_transform(train_features) #.fit: train\n",
        "\n",
        "test_features_vec = vec.transform(test_features)\n",
        "\n",
        "def pos_cats(pos_list):\n",
        "\tcat_d = {}\n",
        "\tfor idx, x in enumerate(list(set(pos_list))):\n",
        "\t\tcat_d[x] = idx\n",
        "\treturn(cat_d)\n",
        "\n",
        "def convert_pos(pos_list,pos_d):\n",
        "\tconverted = []\n",
        "\tfor x in pos_list:\n",
        "\t\tconverted.append(pos_d[x])\n",
        "\treturn(converted)\n",
        "\n",
        "def extract_pred_pos(pred_array,rev_d):\n",
        "  predicted = []\n",
        "  for x in pred_array:\n",
        "    predicted.append(rev_d[x])\n",
        "  return (predicted)\n",
        "\n",
        "pos_d = pos_cats(flat_pos) #create pos to number dictionary\n",
        "rev_pos_d = {value: key for (key, value) in pos_d.items()} #create number to POS dictionary for decoding output\n",
        "train_pos_num = convert_pos(train_pos,pos_d) #convert training pos tags to numbers\n",
        "\n",
        "print(pos_d)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'INTJ': 0, 'NUM': 1, 'PRON': 2, 'SCONJ': 3, 'PART': 4, 'PROPN': 5, 'ADP': 6, 'ADV': 7, 'SYM': 8, 'NOUN': 9, 'AUX': 10, 'X': 11, 'VERB': 12, 'ADJ': 13, 'DET': 14, 'CCONJ': 15, 'PUNCT': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA969t63jZdr",
        "outputId": "0bf098f7-647c-4a60-bd24-f1ef788d2df1"
      },
      "source": [
        "train_pos_num[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15, 7, 7, 7, 3, 14, 9, 12, 9, 13]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8kkO9gRjeBk"
      },
      "source": [
        "from sklearn import tree \n",
        "\n",
        "clf = tree.DecisionTreeClassifier() \n",
        "clf = clf.fit(train_features_vec,train_pos_num) \n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbXKxOo5pIr"
      },
      "source": [
        "**[Step 6]** Simple and Refined Accuracy\n",
        "\n",
        "With the model above, now we will\n",
        "\n",
        "(1) test its overall accuracy\n",
        "(2) its by-tag accuracy\n",
        "(3) try some test sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHZLOVkjrBx"
      },
      "source": [
        "# accuracy\n",
        "def pred_accuracy(pred,gold):\n",
        "\tc = 0\n",
        "\tf = 0\n",
        "\n",
        "\tfor idx, x in enumerate(pred):\n",
        "\t\t#print(x,gold[idx][\"pos\"])\n",
        "\t\tif x == gold[idx]:\n",
        "\t\t\tc+=1\n",
        "\t\telse:\n",
        "\t\t\tf+=1\n",
        "\treturn(c/(c+f))\n",
        "\n",
        "def prec_rec(accuracy_dict):\n",
        "\taccuracy_dict[\"TC\"] = accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"]\n",
        "\tif accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"] == 0:\n",
        "\t\taccuracy_dict[\"recall\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"recall\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"])\n",
        "\n",
        "\tif accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"] == 0:\n",
        "\t\taccuracy_dict[\"precision\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"precision\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"])\n",
        "\tif accuracy_dict[\"precision\"] == 0 and accuracy_dict[\"recall\"] == 0:\n",
        "\t\taccuracy_dict[\"f1\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"f1\"] = 2 * ((accuracy_dict[\"precision\"] * accuracy_dict[\"recall\"])/(accuracy_dict[\"precision\"] + accuracy_dict[\"recall\"]))\n",
        "\n",
        "\n",
        "def tag_prec_rec_flat(tested,gold):\n",
        "\ttag_d = {}\n",
        "\n",
        "\tfor idx, item in enumerate(gold):\n",
        "\t\t### convert formats, as needed: ###\n",
        "\t\tif type(item) == str:\n",
        "\t\t\titem = {\"pos\" : item}\n",
        "\n",
        "\t\tif type(tested[idx]) == str:\n",
        "\t\t\ttested[idx] = {\"pos\" : tested[idx]}\n",
        "\n",
        "\t\t### update tag dictionary as needed ###\n",
        "\t\tif item[\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[item[\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\t\tif tested[idx][\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\n",
        "\t\t### tabulate accuracy ###\n",
        "\t\tif item[\"pos\"] == tested[idx][\"pos\"]:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"TP\"] += 1\n",
        "\t\telse:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"FN\"] += 1\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]][\"FP\"] += 1\n",
        "\n",
        "\tfor x in tag_d:\n",
        "\t\tprec_rec(tag_d[x])\n",
        "\n",
        "\treturn(tag_d)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M35j0naZjmVc",
        "outputId": "90854294-4e45-409d-8de1-a4d1816334a1"
      },
      "source": [
        "clf_pred = clf.predict(test_features_vec)\n",
        "# process train data and convert it from numbers to POS tags\n",
        "clf_pred_pos = extract_pred_pos(clf_pred, rev_pos_d)\n",
        "clf_pred_pos[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'VERB', 'ADV', 'PUNCT', 'VERB', 'NOUN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMpbCqIxAGQa",
        "outputId": "7c263a8b-71a7-4c36-9ef4-144da3e152a1"
      },
      "source": [
        "# check simple accuracy\n",
        "pred_accuracy(clf_pred_pos,test_pos)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8063688407278675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0N_2n7oAL_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce75631-34df-4fc5-9c30-c325a03a4a01"
      },
      "source": [
        "# check by-tag accuracy \n",
        "\n",
        "pred_by_tag_accuracy = tag_prec_rec_flat(clf_pred_pos, test_pos)\n",
        "print(pred_by_tag_accuracy)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ADJ': {'TP': 3127, 'FP': 258, 'FN': 939, 'TC': 4066, 'recall': 0.7690605017215937, 'precision': 0.9237813884785819, 'f1': 0.8393504227620453}, 'NOUN': {'TP': 27823, 'FP': 14264, 'FN': 960, 'TC': 28783, 'recall': 0.9666469791196192, 'precision': 0.6610829947489724, 'f1': 0.7851841399746013}, 'VERB': {'TP': 11551, 'FP': 1607, 'FN': 4991, 'TC': 16542, 'recall': 0.6982831580220046, 'precision': 0.8778689770481836, 'f1': 0.7778451178451178}, 'ADV': {'TP': 10233, 'FP': 334, 'FN': 3407, 'TC': 13640, 'recall': 0.7502199413489736, 'precision': 0.9683921642850384, 'f1': 0.8454579253934813}, 'PUNCT': {'TP': 10607, 'FP': 0, 'FN': 48, 'TC': 10655, 'recall': 0.9954950727358047, 'precision': 1.0, 'f1': 0.9977424513216065}, 'SCONJ': {'TP': 3797, 'FP': 636, 'FN': 1175, 'TC': 4972, 'recall': 0.7636765888978279, 'precision': 0.8565305662079855, 'f1': 0.8074428495481129}, 'AUX': {'TP': 2808, 'FP': 469, 'FN': 730, 'TC': 3538, 'recall': 0.7936687394007914, 'precision': 0.8568812938663412, 'f1': 0.8240645634629494}, 'CCONJ': {'TP': 3775, 'FP': 522, 'FN': 1734, 'TC': 5509, 'recall': 0.6852423307315302, 'precision': 0.8785198976029788, 'f1': 0.7699367734040382}, 'PRON': {'TP': 1710, 'FP': 110, 'FN': 484, 'TC': 2194, 'recall': 0.7793983591613491, 'precision': 0.9395604395604396, 'f1': 0.852017937219731}, 'DET': {'TP': 1396, 'FP': 185, 'FN': 116, 'TC': 1512, 'recall': 0.9232804232804233, 'precision': 0.8829854522454142, 'f1': 0.902683478823149}, 'NUM': {'TP': 674, 'FP': 172, 'FN': 842, 'TC': 1516, 'recall': 0.4445910290237467, 'precision': 0.7966903073286052, 'f1': 0.5707027942421676}, 'PROPN': {'TP': 822, 'FP': 347, 'FN': 3207, 'TC': 4029, 'recall': 0.20402084884586746, 'precision': 0.7031650983746792, 'f1': 0.31627549057329746}, 'ADP': {'TP': 425, 'FP': 19, 'FN': 55, 'TC': 480, 'recall': 0.8854166666666666, 'precision': 0.9572072072072072, 'f1': 0.9199134199134199}, 'X': {'TP': 99, 'FP': 10, 'FN': 183, 'TC': 282, 'recall': 0.35106382978723405, 'precision': 0.908256880733945, 'f1': 0.5063938618925832}, 'PART': {'TP': 7, 'FP': 8, 'FN': 59, 'TC': 66, 'recall': 0.10606060606060606, 'precision': 0.4666666666666667, 'f1': 0.1728395061728395}, 'SYM': {'TP': 24, 'FP': 0, 'FN': 9, 'TC': 33, 'recall': 0.7272727272727273, 'precision': 1.0, 'f1': 0.8421052631578948}, 'INTJ': {'TP': 1, 'FP': 0, 'FN': 2, 'TC': 3, 'recall': 0.3333333333333333, 'precision': 1.0, 'f1': 0.5}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fg7uTUAtuo",
        "outputId": "3ba79f90-4d12-4b97-c7e2-a913a6950b00"
      },
      "source": [
        "#sort data by frequency (\"TC\")\n",
        "from operator import *\n",
        "pred_by_tag_accuracy_sorted = sorted(pred_by_tag_accuracy.items(),key=lambda x:getitem(x[1],'TC'), reverse = True)\n",
        "\n",
        "#output F1 score of top ten most frequent tags\n",
        "for x in pred_by_tag_accuracy_sorted[:10]:\n",
        "\tprint(x[0], x[1][\"f1\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOUN 0.7851841399746013\n",
            "VERB 0.7778451178451178\n",
            "ADV 0.8454579253934813\n",
            "PUNCT 0.9977424513216065\n",
            "CCONJ 0.7699367734040382\n",
            "SCONJ 0.8074428495481129\n",
            "ADJ 0.8393504227620453\n",
            "PROPN 0.31627549057329746\n",
            "AUX 0.8240645634629494\n",
            "PRON 0.852017937219731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVL8T_VNDVOn"
      },
      "source": [
        "''' \n",
        "Try a few test cases to see how our tagger does on particular words in particular contexts\n",
        "'''\n",
        "\n",
        "def tagger(model,vec,rev_dict,extractor,token_list):\n",
        "\ttagged = [] #for final word + tag output\n",
        "\n",
        "\tfor sent in token_list:\n",
        "\t\tfeatures = [] #in progress tagging list\n",
        "\t\ttagging = [] #final word-tag pairs\n",
        "\n",
        "\t\tfor idx, token in enumerate(sent):\n",
        "\t\t\tfeatures.append({\"word\" : token}) # add word to feature set\n",
        "\t\t\t#print(features,idx,features[idx])\n",
        "\t\t\tfeatures[idx] = extractor(features,idx,features[idx]) #add featured token to features list\n",
        "\t\t\t#print(features)\n",
        "\t\t\t#print(vec.transform(features[idx]))\n",
        "\t\t\t#print(model.predict(vec.transform([features[idx]])))\n",
        "\t\t\tfeatures[idx][\"pos\"] = rev_dict[model.predict(vec.transform([features[idx]]))[0]] #add pos to features - this happens one token at a time\n",
        "\t\t\ttagging.append({\"word\" : token, \"pos\" : features[idx][\"pos\"]}) #add word-tag pairs to sentence level output\n",
        "\t\ttagged.append(tagging) #add sentence to output\n",
        "\n",
        "\treturn(tagged)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xR7Ed65EmZN",
        "outputId": "b59575af-2c09-48b3-e486-a98bc8df87ab"
      },
      "source": [
        "sample1 = [\"후반작업을 이유로 불참 예정이던 김원석 감독은 제작발표회장에 깜짝 등장해 \"\"\"\"기대는 낮추시고 응원하는 마음으로 봐달라\"\"\"\"고 당부했다.\".split(\" \")]\n",
        "final1 = tagger(clf, vec, rev_pos_d, simple_features, sample1)\n",
        "\n",
        "for i in final1:\n",
        "  for j in i:\n",
        "    print(j, sep='\\n')\n",
        "  print()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': '후반작업을', 'pos': 'NOUN'}\n",
            "{'word': '이유로', 'pos': 'NOUN'}\n",
            "{'word': '불참', 'pos': 'NOUN'}\n",
            "{'word': '예정이던', 'pos': 'VERB'}\n",
            "{'word': '김원석', 'pos': 'NOUN'}\n",
            "{'word': '감독은', 'pos': 'NOUN'}\n",
            "{'word': '제작발표회장에', 'pos': 'ADV'}\n",
            "{'word': '깜짝', 'pos': 'ADV'}\n",
            "{'word': '등장해', 'pos': 'VERB'}\n",
            "{'word': '기대는', 'pos': 'NOUN'}\n",
            "{'word': '낮추시고', 'pos': 'NOUN'}\n",
            "{'word': '응원하는', 'pos': 'VERB'}\n",
            "{'word': '마음으로', 'pos': 'ADV'}\n",
            "{'word': '봐달라고', 'pos': 'VERB'}\n",
            "{'word': '당부했다.', 'pos': 'NOUN'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxJxw3-Z_pwy",
        "outputId": "0e05f73f-b28b-46e6-c358-ca95873db5fa"
      },
      "source": [
        "sample2 = [\"세종은 조선의 네 번째 국왕이며 그의 업적에 대한 존경의 의미를 담은 명칭인 세종대왕으로 자주 일컬어진다.\".split(\" \")]\n",
        "final2 = tagger(clf, vec, rev_pos_d, simple_features, sample2)\n",
        "\n",
        "for i in final2:\n",
        "  for j in i:\n",
        "    print(j, sep='\\n')\n",
        "  print()\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': '세종은', 'pos': 'PROPN'}\n",
            "{'word': '조선의', 'pos': 'NOUN'}\n",
            "{'word': '네', 'pos': 'NOUN'}\n",
            "{'word': '번째', 'pos': 'NOUN'}\n",
            "{'word': '국왕이며', 'pos': 'CCONJ'}\n",
            "{'word': '그의', 'pos': 'PRON'}\n",
            "{'word': '업적에', 'pos': 'NOUN'}\n",
            "{'word': '대한', 'pos': 'VERB'}\n",
            "{'word': '존경의', 'pos': 'PROPN'}\n",
            "{'word': '의미를', 'pos': 'NOUN'}\n",
            "{'word': '담은', 'pos': 'NOUN'}\n",
            "{'word': '명칭인', 'pos': 'NOUN'}\n",
            "{'word': '세종대왕으로', 'pos': 'ADV'}\n",
            "{'word': '자주', 'pos': 'ADV'}\n",
            "{'word': '일컬어진다.', 'pos': 'VERB'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}