{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Korean_POS_tagging_ver.2_morphemes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60EWtX8JFxC"
      },
      "source": [
        "**[Step 1]** Upload the file(\"ko_kaist-du-train.conllu.txt\") and read it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndc9HHnrFTTv",
        "outputId": "113ec2f1-344d-4b62-8b5b-9112df048153"
      },
      "source": [
        "f = open('ko_kaist-ud-train.conllu.txt', 'r', encoding='utf-8') # encoding='utf-8' : Korean data set\n",
        "\n",
        "f_lines = f.readlines() #read by lines\n",
        "f.close()\n",
        "\n",
        "len(f_lines) #365476\n",
        "f_lines[:10] #sample_test_lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# sent_id = M2TA_064-s1\\n',\n",
              " '# text = 하기야 짐승도 잘 가르치기만 하면 어느 정도는 순치될 수 있다.\\n',\n",
              " '1\\t하기야\\t하기야\\tCCONJ\\tmaj\\t_\\t8\\tcc\\t_\\t_\\n',\n",
              " '2\\t짐승도\\t짐승+도\\tADV\\tncn+jxc\\t_\\t8\\tadvcl\\t_\\t_\\n',\n",
              " '3\\t잘\\t잘\\tADV\\tmag\\t_\\t4\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t가르치기만\\t가르치+기+만\\tADV\\tpvg+etn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t하면\\t하+면\\tSCONJ\\tpvg+ecs\\t_\\t8\\tccomp\\t_\\t_\\n',\n",
              " '6\\t어느\\t어느\\tDET\\tmmd\\t_\\t7\\tdet\\t_\\t_\\n',\n",
              " '7\\t정도는\\t정도+는\\tNOUN\\tncn+jxt\\t_\\t8\\tdislocated\\t_\\t_\\n',\n",
              " '8\\t순치될\\t순치+되+ㄹ\\tVERB\\tncpa+xsv+etm\\t_\\t0\\troot\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzeOquW89sg0",
        "outputId": "90491fdb-3f0a-4bc6-c8b2-b47560801975"
      },
      "source": [
        "f_lines[25:35] #check that some datas '\\n' and '# sent (or text)...' have to be deleted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10\\t.\\t.\\tPUNCT\\tsf\\t_\\t9\\tpunct\\t_\\t_\\n',\n",
              " '\\n',\n",
              " '# sent_id = M2TA_064-s3\\n',\n",
              " '# text = 뭇 짐승들은 일단 배만 부르면 더 이상의 탐욕을 부리지 않는다.\\n',\n",
              " '1\\t뭇\\t뭇\\tADJ\\tmma\\t_\\t2\\tamod\\t_\\t_\\n',\n",
              " '2\\t짐승들은\\t짐승+들+은\\tNOUN\\tncn+xsn+jxt\\t_\\t9\\tdislocated\\t_\\t_\\n',\n",
              " '3\\t일단\\t일단\\tADV\\tmag\\t_\\t5\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t배만\\t배+만\\tADV\\tncn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t부르면\\t부르+면\\tSCONJ\\tpaa+ecs\\t_\\t9\\txcomp\\t_\\t_\\n',\n",
              " '6\\t더\\t더\\tADV\\tmag\\t_\\t7\\tadvmod\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pym53fcI4CPd"
      },
      "source": [
        "index = []\n",
        "word = []\n",
        "pos = []\n",
        "\n",
        "word_num = 1\n",
        "\n",
        "for i, line in enumerate(f_lines):\n",
        "    line = line.strip()\n",
        "    splits = line.split('\\t')\n",
        "    \n",
        "    if len(splits) > 2:\n",
        "        try:\n",
        "            idx = int(splits[0])\n",
        "            words = splits[2].split('+')\n",
        "            poses = splits[4].split('+')\n",
        "            for w, p in zip(words, poses):\n",
        "                index.append(word_num)\n",
        "                word.append(w)\n",
        "                pos.append(p)\n",
        "                word_num += 1\n",
        "\n",
        "            if idx == 1 and word_num != 1:\n",
        "                word_num = 1\n",
        "\n",
        "            #word.append(splits[1])\n",
        "            #pos.append(splits[3])\n",
        "        \n",
        "        except:\n",
        "            print (i, index[-5:], word[-5:], pos[-5:])\n",
        "            print (line)\n",
        "            #index.append("
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2QJ145p73r2",
        "outputId": "4339f760-075b-449f-800b-0a11dceeeb64"
      },
      "source": [
        "print(index[:20])\n",
        "print(word[:20])\n",
        "print(pos[:20])\n",
        "\n",
        "#check\n",
        "len(index) #588539\n",
        "print(set(index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "['하기야', '짐승', '도', '잘', '가르치', '기', '만', '하', '면', '어느', '정도', '는', '순치', '되', 'ㄹ', '수', '있', '다', '.', '사람']\n",
            "['maj', 'ncn', 'jxc', 'mag', 'pvg', 'etn', 'jxc', 'pvg', 'ecs', 'mmd', 'ncn', 'jxt', 'ncpa', 'xsv', 'etm', 'nbn', 'paa', 'ef', 'sf', 'ncn']\n",
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMl9KG4rKI2s",
        "outputId": "26fdf10f-024c-4741-e3d5-d032482caca4"
      },
      "source": [
        "len(index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "588539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piLQQn3yJccY"
      },
      "source": [
        "**[Step 2]** Format the data\n",
        "1. Represent the data as a list of dictionaries\n",
        "2. Represent words as dictionaries with multiple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWablQWF88-e"
      },
      "source": [
        "input_data = [] #total test sentences\n",
        "\n",
        "sent = [] #iterate through sentence\n",
        "i = 0\n",
        "pos_index = 0\n",
        "\n",
        "while (i < len(index)):\n",
        "    if (int(index[i])) == pos_index + 1:\n",
        "          sent.append({\"word\" :word[i], \"pos\" :pos[i]})\n",
        "          pos_index += 1\n",
        "          i = i +1\n",
        "    else:\n",
        "        if sent:\n",
        "            input_data.append(sent) #to filterout empty index\n",
        "        else:\n",
        "            i = i +1\n",
        "        pos_index = 0 #new sentence, make the number of sentence to default number\n",
        "        sent = []\n",
        "        if i == (len(index)-1):\n",
        "            break\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print (i, len(index)) #check if there is no infinite loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmyF4hEA4JA",
        "outputId": "2879557f-eaa9-43a6-80d7-1e70a40a0acc"
      },
      "source": [
        "len(input_data) #23010"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQXCPh0A_fF",
        "outputId": "97b9f372-3414-4c44-b337-ec9cdd162a25"
      },
      "source": [
        "print (input_data[1][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'word': '짐승', 'pos': 'ncn'}, {'word': '도', 'pos': 'jxc'}, {'word': '잘', 'pos': 'mag'}, {'word': '가르치', 'pos': 'pvg'}, {'word': '기', 'pos': 'etn'}, {'word': '만', 'pos': 'jxc'}, {'word': '하', 'pos': 'pvg'}, {'word': '면', 'pos': 'ecs'}, {'word': '어느', 'pos': 'mmd'}, {'word': '정도', 'pos': 'ncn'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybzN8QNKqXa"
      },
      "source": [
        "**[Step 3]** Check frequency dict (Optional, just for fun)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXm0VFP3L2Mj",
        "outputId": "3ac2e70d-b88b-465b-c8ef-77e37ac38348"
      },
      "source": [
        "def freq_add(item, d):\n",
        "    if item not in d:\n",
        "        d[item] = 1\n",
        "    else:\n",
        "        d[item] += 1\n",
        "\n",
        "# iterate through sentences, get tabulate tags for each word\n",
        "def tag_freq(data_set):\n",
        "    freq = {}\n",
        "    for sent in data_set:\n",
        "        for item in sent:\n",
        "            if item[\"word\"] not in freq:\n",
        "                freq[item[\"word\"]] = {}\n",
        "            freq_add(item[\"pos\"], freq[item[\"word\"]])\n",
        "\n",
        "    return (freq)\n",
        "\n",
        "#create frequency dic\n",
        "word_tags = tag_freq(input_data)\n",
        "\n",
        "#check\n",
        "print(word_tags[\"사람\"]) #'human' in Korean\n",
        "print(word_tags[\"사랑\"]) #'love' in Korean\n",
        "print(word_tags[\"가\"]) #ambiguous without context, 'go' or 'postposition' after noun\n",
        "print(word_tags[\"는\"]) #ambiguous without context, 'postposition(e.g.,'나는')' or 'verbal ending(e.g.,'가는')'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ncn': 1237}\n",
            "{'ncpa': 124, 'ncn': 4, 'ncps': 8}\n",
            "{'jcc': 351, 'jcs': 5560, 'px': 613, 'pvg': 202, 'ncn': 10, 'ef': 1, 'nq': 1, 'jcr': 1, 'jxt': 1}\n",
            "{'jxt': 9559, 'etm': 8752, 'jcm': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeyp7AVWiLk"
      },
      "source": [
        "**[Step 4]** Format the data for scikit-learn and extract features\n",
        "1. Add some features\n",
        "2. Flat the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMnd1DkuXOba"
      },
      "source": [
        "def simple_features(input_sent, idx, token):\n",
        "\n",
        "  features = {}\n",
        "  features[\"word\"] = token[\"word\"]\n",
        "  features[\"pos\"] = token[\"pos\"]\n",
        "\n",
        "  if idx == 0:\n",
        "      features[\"prev_pos\"] = \"<start>\"\n",
        "      features[\"prev_prev_pos\"] = \"<start>_<start>\"\n",
        "\n",
        "  elif idx == 1:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = \"<start>_\"+ input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_word\"] = input_sent[idx-1][\"word\"]\n",
        "\n",
        "  else:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = input_sent[idx-2][\"pos\"]\n",
        "\n",
        "  features[\"suffix_tg\"] = token[\"word\"][-2:]\n",
        "\n",
        "  return (features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpFsobMIcSne"
      },
      "source": [
        "def feature_extractor(input_data): \n",
        "\tfeature_list = [] \n",
        "\tfor sent in input_data: \n",
        "\t\tfor idx, token in enumerate(sent): \n",
        "\t\t\tfeature_list.append(simple_features(sent,idx,token)) \n",
        "\treturn(feature_list)\n",
        "\n",
        "def extract_pos(input_data):\n",
        "\tpos_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tpos_list.append(token[\"pos\"])\n",
        "\treturn(pos_list)\n",
        "\n",
        "def extract_words(input_data):\n",
        "\tword_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tword_list.append(token[\"word\"])\n",
        "\treturn(word_list)\n",
        "\n",
        "flat_words = extract_words(input_data)\n",
        "flat_pos = extract_pos(input_data)\n",
        "flat_features = feature_extractor(input_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoodUaGMdRo0",
        "outputId": "e2a2c867-bd59-499f-f72e-ccb986dbcc28"
      },
      "source": [
        "for idx, x in enumerate(flat_words[50:60]):\n",
        "  print(x, flat_pos[idx], flat_features[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "탐욕 maj {'word': '하기야', 'pos': 'maj', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '기야'}\n",
            "을 ncn {'word': '짐승', 'pos': 'ncn', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '짐승'}\n",
            "부리 jxc {'word': '도', 'pos': 'jxc', 'prev_pos': 'ncn', 'prev_prev_pos': '<start>_ncn', 'prev_word': '짐승', 'suffix_tg': '도'}\n",
            "지 mag {'word': '잘', 'pos': 'mag', 'prev_pos': 'jxc', 'prev_prev_pos': 'ncn', 'suffix_tg': '잘'}\n",
            "않 pvg {'word': '가르치', 'pos': 'pvg', 'prev_pos': 'mag', 'prev_prev_pos': 'jxc', 'suffix_tg': '르치'}\n",
            "는다 etn {'word': '기', 'pos': 'etn', 'prev_pos': 'pvg', 'prev_prev_pos': 'mag', 'suffix_tg': '기'}\n",
            ". jxc {'word': '만', 'pos': 'jxc', 'prev_pos': 'etn', 'prev_prev_pos': 'pvg', 'suffix_tg': '만'}\n",
            "우거지 pvg {'word': '하', 'pos': 'pvg', 'prev_pos': 'jxc', 'prev_prev_pos': 'etn', 'suffix_tg': '하'}\n",
            "ㄴ ecs {'word': '면', 'pos': 'ecs', 'prev_pos': 'pvg', 'prev_prev_pos': 'jxc', 'suffix_tg': '면'}\n",
            "쑥밭 mmd {'word': '어느', 'pos': 'mmd', 'prev_pos': 'ecs', 'prev_prev_pos': 'pvg', 'suffix_tg': '어느'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kol12yF1LMNo",
        "outputId": "0927d576-6f3b-464c-e959-e5d04a328a78"
      },
      "source": [
        "# Training and test sets\n",
        "\n",
        "print(len(flat_words)*.67) #394295\n",
        "\n",
        "#training data\n",
        "train_words = flat_words[:394295]\n",
        "train_pos = flat_pos[:394295]\n",
        "train_features = flat_features[:394295]\n",
        "\n",
        "#test data\n",
        "test_words = flat_words[394295:]\n",
        "test_pos = flat_pos[394295:]\n",
        "test_features = flat_features[394295:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "394295.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmQ8jhnihyJ"
      },
      "source": [
        "**[Step 5]** Use scikit-learn for POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbxkJxZjEdr",
        "outputId": "dee7a12c-f8a4-4dc8-c1a6-408d89bd2d54"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse = True)\n",
        "\n",
        "train_features_vec = vec.fit_transform(train_features) #.fit: train\n",
        "\n",
        "test_features_vec = vec.transform(test_features)\n",
        "\n",
        "def pos_cats(pos_list):\n",
        "\tcat_d = {}\n",
        "\tfor idx, x in enumerate(list(set(pos_list))):\n",
        "\t\tcat_d[x] = idx\n",
        "\treturn(cat_d)\n",
        "\n",
        "pos_d = pos_cats(flat_pos)\n",
        "\n",
        "def convert_pos(pos_list,pos_d):\n",
        "\tconverted = []\n",
        "\tfor x in pos_list:\n",
        "\t\tconverted.append(pos_d[x])\n",
        "\treturn(converted)\n",
        "\n",
        "train_pos_num = convert_pos(train_pos,pos_d)\n",
        "\n",
        "print(pos_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ncn': 0, 'jcj': 1, 'mmd': 2, 'xsa': 3, 'ii': 4, 'ecx': 5, 'jct': 6, 'sf': 7, 'nbn': 8, 'sp': 9, 'f': 10, 'sr': 11, 'jcr': 12, 'nq': 13, 'ecs': 14, 'pad': 15, 'maj': 16, 'xsm': 17, 'etm': 18, 'mad': 19, 'pvg': 20, 'xsv': 21, 'paa': 22, 'pvd': 23, 'ncps': 24, 'nbu': 25, 'jcm': 26, 'jxc': 27, 'xsn': 28, 'xp': 29, 'mag': 30, 'jcv': 31, 'ep': 32, 'sl': 33, 'jp': 34, 'jcs': 35, 'jca': 36, 'jxf': 37, 'nnc': 38, 'mma': 39, 'su': 40, 'jcc': 41, 'npp': 42, 'ecc': 43, 'px': 44, 'jco': 45, 'jxt': 46, 'ncpa': 47, 'ef': 48, 'etn': 49, 'npd': 50, 'nno': 51}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA969t63jZdr",
        "outputId": "5975aa19-a83e-45c1-ec7e-edbbba962893"
      },
      "source": [
        "train_pos_num[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16, 0, 27, 30, 20, 49, 27, 20, 14, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8kkO9gRjeBk",
        "outputId": "f79dbfa1-9392-4e41-98a4-50a163d9fc26"
      },
      "source": [
        "from sklearn import tree \n",
        "\n",
        "clf = tree.DecisionTreeClassifier() \n",
        "clf = clf.fit(train_features_vec,train_pos_num) \n",
        "\n",
        "pred1 = clf.predict(test_features_vec) \n",
        "\n",
        "print(pred1[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43  9 47 28 27 22 43 30  0 26]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M35j0naZjmVc",
        "outputId": "3d7da3cd-f83a-44d3-d491-06af3812df4f"
      },
      "source": [
        "rev_pos_d = {value : key for (key, value) in pos_d.items()}\n",
        "\n",
        "def extract_pred_pos(pred_array,rev_d):\n",
        "\tpredicted = []\n",
        "\tfor x in pred_array:\n",
        "\t\tpredicted.append(rev_d[x])\n",
        "\treturn(predicted)\n",
        "\n",
        "pred1_pos = extract_pred_pos(pred1,rev_pos_d)\n",
        "pred1_pos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ecc', 'sp', 'ncpa', 'xsn', 'jxc', 'paa', 'ecc', 'mag', 'ncn', 'jcm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhHZLOVkjrBx",
        "outputId": "14049c15-c418-4470-c5b6-c6cba8a282a5"
      },
      "source": [
        "def pred_accuracy(pred,gold):\n",
        "\tc = 0\n",
        "\tf = 0\n",
        "\n",
        "\tfor idx, x in enumerate(pred):\n",
        "\t\t#print(x,gold[idx][\"pos\"])\n",
        "\t\tif x == gold[idx]:\n",
        "\t\t\tc+=1\n",
        "\t\telse:\n",
        "\t\t\tf+=1\n",
        "\treturn(c/(c+f))\n",
        "\n",
        "pred_accuracy(pred1_pos,test_pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999948508019876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}