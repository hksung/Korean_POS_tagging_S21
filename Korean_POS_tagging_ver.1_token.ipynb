{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Korean_POS_tagging_ver.1_token.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60EWtX8JFxC"
      },
      "source": [
        "**[Step 1]** Upload the file(\"ko_kaist-du-train.conllu.txt\") and read it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndc9HHnrFTTv",
        "outputId": "aa51dbac-d452-4533-96a9-dd0125aef054"
      },
      "source": [
        "f = open('ko_kaist-ud-train.conllu.txt', 'r', encoding='utf-8') # encoding='utf-8' : Korean data set\n",
        "\n",
        "f_lines = f.readlines() #read by lines\n",
        "f.close()\n",
        "\n",
        "len(f_lines) #365476\n",
        "f_lines[:10] #sample_test_lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# sent_id = M2TA_064-s1\\n',\n",
              " '# text = 하기야 짐승도 잘 가르치기만 하면 어느 정도는 순치될 수 있다.\\n',\n",
              " '1\\t하기야\\t하기야\\tCCONJ\\tmaj\\t_\\t8\\tcc\\t_\\t_\\n',\n",
              " '2\\t짐승도\\t짐승+도\\tADV\\tncn+jxc\\t_\\t8\\tadvcl\\t_\\t_\\n',\n",
              " '3\\t잘\\t잘\\tADV\\tmag\\t_\\t4\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t가르치기만\\t가르치+기+만\\tADV\\tpvg+etn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t하면\\t하+면\\tSCONJ\\tpvg+ecs\\t_\\t8\\tccomp\\t_\\t_\\n',\n",
              " '6\\t어느\\t어느\\tDET\\tmmd\\t_\\t7\\tdet\\t_\\t_\\n',\n",
              " '7\\t정도는\\t정도+는\\tNOUN\\tncn+jxt\\t_\\t8\\tdislocated\\t_\\t_\\n',\n",
              " '8\\t순치될\\t순치+되+ㄹ\\tVERB\\tncpa+xsv+etm\\t_\\t0\\troot\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzeOquW89sg0",
        "outputId": "15821da9-3722-43fc-be3a-0b171ca7c4a9"
      },
      "source": [
        "f_lines[25:35] #check that some datas '\\n' and '# sent (or text)...' have to be deleted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10\\t.\\t.\\tPUNCT\\tsf\\t_\\t9\\tpunct\\t_\\t_\\n',\n",
              " '\\n',\n",
              " '# sent_id = M2TA_064-s3\\n',\n",
              " '# text = 뭇 짐승들은 일단 배만 부르면 더 이상의 탐욕을 부리지 않는다.\\n',\n",
              " '1\\t뭇\\t뭇\\tADJ\\tmma\\t_\\t2\\tamod\\t_\\t_\\n',\n",
              " '2\\t짐승들은\\t짐승+들+은\\tNOUN\\tncn+xsn+jxt\\t_\\t9\\tdislocated\\t_\\t_\\n',\n",
              " '3\\t일단\\t일단\\tADV\\tmag\\t_\\t5\\tadvmod\\t_\\t_\\n',\n",
              " '4\\t배만\\t배+만\\tADV\\tncn+jxc\\t_\\t5\\tadvcl\\t_\\t_\\n',\n",
              " '5\\t부르면\\t부르+면\\tSCONJ\\tpaa+ecs\\t_\\t9\\txcomp\\t_\\t_\\n',\n",
              " '6\\t더\\t더\\tADV\\tmag\\t_\\t7\\tadvmod\\t_\\t_\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pym53fcI4CPd"
      },
      "source": [
        "index = []\n",
        "word = []\n",
        "pos = []\n",
        "\n",
        "for i, line in enumerate(f_lines):\n",
        "    line = line.strip() # delete '\\n'\n",
        "    splits = line.split('\\t') # split by '\\t'\n",
        "\n",
        "    if len(splits) > 2: # filter '\\n\\'\n",
        "        try:\n",
        "            idx = int(splits[0]) # filter 'data starting with '#'\n",
        "            index.append(idx)\n",
        "            word.append(splits[1])\n",
        "            pos.append(splits[3])\n",
        "\n",
        "        except:\n",
        "            print(i, index[-5:], word[-5:], pos[-5:])\n",
        "            print(line) #check if there is an error in idx\n",
        "            # or use print(set(index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2QJ145p73r2",
        "outputId": "51d472da-ac22-42e0-fba9-f32db255ff47"
      },
      "source": [
        "print(index[:20])\n",
        "print(word[:20])\n",
        "print(pos[:20])\n",
        "\n",
        "#check\n",
        "len(index) #296446\n",
        "len(word) #296446\n",
        "len(pos) #296446\n",
        "print(set(index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "['하기야', '짐승도', '잘', '가르치기만', '하면', '어느', '정도는', '순치될', '수', '있다', '.', '사람이', '스스로', '만물의', '영장이라', '하고', '우쭐대는', '까닭이', '여기에', '있다']\n",
            "['CCONJ', 'ADV', 'ADV', 'ADV', 'SCONJ', 'DET', 'NOUN', 'VERB', 'NOUN', 'ADJ', 'PUNCT', 'NOUN', 'ADV', 'NOUN', 'SCONJ', 'SCONJ', 'VERB', 'NOUN', 'ADV', 'ADJ']\n",
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMl9KG4rKI2s",
        "outputId": "fee8838a-cec9-4fd4-852f-e9ae2c5319e3"
      },
      "source": [
        "len(index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piLQQn3yJccY"
      },
      "source": [
        "**[Step 2]** Format the data\n",
        "1. Represent the data as a list of dictionaries\n",
        "2. Represent words as dictionaries with multiple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWablQWF88-e"
      },
      "source": [
        "input_data = [] #total test sentences\n",
        "\n",
        "sent = [] #iterate through sentence\n",
        "i = 0\n",
        "pos_index = 0\n",
        "\n",
        "while (i < len(index)):\n",
        "    if (int(index[i])) == pos_index + 1:\n",
        "          sent.append({\"word\" :word[i], \"pos\" :pos[i]})\n",
        "          pos_index += 1\n",
        "          i = i +1\n",
        "    else:\n",
        "        if sent:\n",
        "            input_data.append(sent) #to filterout empty index\n",
        "        else:\n",
        "            i = i +1\n",
        "        pos_index = 0 #new sentence, make the number of sentence to default number\n",
        "        sent = []\n",
        "        if i == (len(index)-1):\n",
        "            break\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print (i, len(index)) #check if there is no infinite loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmyF4hEA4JA",
        "outputId": "bf3830cb-5ce6-4ecf-fad2-5d1050943f30"
      },
      "source": [
        "len(input_data) #23009 (the number of total sentences, average 12.8 words for a sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQXCPh0A_fF",
        "outputId": "b55b1217-92c8-42e2-a48d-f8d055b9d65c"
      },
      "source": [
        "print (input_data[1][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'word': '사람이', 'pos': 'NOUN'}, {'word': '스스로', 'pos': 'ADV'}, {'word': '만물의', 'pos': 'NOUN'}, {'word': '영장이라', 'pos': 'SCONJ'}, {'word': '하고', 'pos': 'SCONJ'}, {'word': '우쭐대는', 'pos': 'VERB'}, {'word': '까닭이', 'pos': 'NOUN'}, {'word': '여기에', 'pos': 'ADV'}, {'word': '있다', 'pos': 'ADJ'}, {'word': '.', 'pos': 'PUNCT'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybzN8QNKqXa"
      },
      "source": [
        "**[Step 3]** Check frequency dict (Optional, just for fun)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXm0VFP3L2Mj",
        "outputId": "eeaea098-9b25-480c-8975-887e10be5d2b"
      },
      "source": [
        "def freq_add(item, d):\n",
        "    if item not in d:\n",
        "        d[item] = 1\n",
        "    else:\n",
        "        d[item] += 1\n",
        "\n",
        "# iterate through sentences, get tabulate tags for each word\n",
        "def tag_freq(data_set):\n",
        "    freq = {}\n",
        "    for sent in data_set:\n",
        "        for item in sent:\n",
        "            if item[\"word\"] not in freq:\n",
        "                freq[item[\"word\"]] = {}\n",
        "            freq_add(item[\"pos\"], freq[item[\"word\"]])\n",
        "\n",
        "    return (freq)\n",
        "\n",
        "#create frequency dic\n",
        "word_tags = tag_freq(input_data)\n",
        "\n",
        "#check\n",
        "print(word_tags[\"사람\"]) #'human' in Korean\n",
        "print(word_tags[\"사랑\"]) #'love' in Korean\n",
        "print(word_tags[\"가\"]) #ambiguous without context, 'go', 'aux' for sub\n",
        "print(word_tags[\"나는\"]) #ambiguous without context, mostly 'I' but sometime 'fly'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NOUN': 38}\n",
            "{'NOUN': 4}\n",
            "{'ADP': 68, 'SCONJ': 2, 'PROPN': 1, 'VERB': 1, 'AUX': 1}\n",
            "{'VERB': 22, 'PRON': 264}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeyp7AVWiLk"
      },
      "source": [
        "**[Step 4]** Format the data for scikit-learn and extract features\n",
        "1. Add some features\n",
        "2. Flat the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMnd1DkuXOba"
      },
      "source": [
        "def simple_features(input_sent, idx, token):\n",
        "\n",
        "  features = {}\n",
        "  features[\"word\"] = token[\"word\"]\n",
        "  #features[\"pos\"] = token[\"pos\"]\n",
        "\n",
        "  if idx == 0:\n",
        "      features[\"prev_pos\"] = \"<start>\"\n",
        "      features[\"prev_prev_pos\"] = \"<start>_<start>\"\n",
        "\n",
        "  elif idx == 1:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = \"<start>_\"+ input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_word\"] = input_sent[idx-1][\"word\"]\n",
        "\n",
        "  else:\n",
        "      features[\"prev_pos\"] = input_sent[idx-1][\"pos\"]\n",
        "      features[\"prev_prev_pos\"] = input_sent[idx-2][\"pos\"]\n",
        "\n",
        "  features[\"suffix_tg\"] = token[\"word\"][-2:]\n",
        "\n",
        "  return (features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpFsobMIcSne"
      },
      "source": [
        "def feature_extractor(input_data): \n",
        "\tfeature_list = [] \n",
        "\tfor sent in input_data: \n",
        "\t\tfor idx, token in enumerate(sent): \n",
        "\t\t\tfeature_list.append(simple_features(sent,idx,token)) \n",
        "\treturn(feature_list)\n",
        "\n",
        "def extract_pos(input_data):\n",
        "\tpos_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tpos_list.append(token[\"pos\"])\n",
        "\treturn(pos_list)\n",
        "\n",
        "def extract_words(input_data):\n",
        "\tword_list = []\n",
        "\tfor sent in input_data:\n",
        "\t\tfor token in sent:\n",
        "\t\t\tword_list.append(token[\"word\"])\n",
        "\treturn(word_list)\n",
        "\n",
        "flat_words = extract_words(input_data)\n",
        "flat_pos = extract_pos(input_data)\n",
        "flat_features = feature_extractor(input_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoodUaGMdRo0",
        "outputId": "dea573a4-d16a-441a-afa7-fbc68c47ab95"
      },
      "source": [
        "for idx, x in enumerate(flat_words[50:60]):\n",
        "  print(x, flat_pos[idx], flat_features[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "생명력이 CCONJ {'word': '하기야', 'prev_pos': '<start>', 'prev_prev_pos': '<start>_<start>', 'suffix_tg': '기야'}\n",
            "있어서 ADV {'word': '짐승도', 'prev_pos': 'CCONJ', 'prev_prev_pos': '<start>_CCONJ', 'prev_word': '하기야', 'suffix_tg': '승도'}\n",
            "뽑기만 ADV {'word': '잘', 'prev_pos': 'ADV', 'prev_prev_pos': 'CCONJ', 'suffix_tg': '잘'}\n",
            "하고 ADV {'word': '가르치기만', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '기만'}\n",
            "그냥 SCONJ {'word': '하면', 'prev_pos': 'ADV', 'prev_prev_pos': 'ADV', 'suffix_tg': '하면'}\n",
            "두면 DET {'word': '어느', 'prev_pos': 'SCONJ', 'prev_prev_pos': 'ADV', 'suffix_tg': '어느'}\n",
            "더 NOUN {'word': '정도는', 'prev_pos': 'DET', 'prev_prev_pos': 'SCONJ', 'suffix_tg': '도는'}\n",
            "무성하게 VERB {'word': '순치될', 'prev_pos': 'NOUN', 'prev_prev_pos': 'DET', 'suffix_tg': '치될'}\n",
            "자라기 NOUN {'word': '수', 'prev_pos': 'VERB', 'prev_prev_pos': 'NOUN', 'suffix_tg': '수'}\n",
            "마련이다 ADJ {'word': '있다', 'prev_pos': 'NOUN', 'prev_prev_pos': 'VERB', 'suffix_tg': '있다'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kol12yF1LMNo",
        "outputId": "9a6130ae-92d9-4322-818e-b9fe89ff036c"
      },
      "source": [
        "# Training and test sets\n",
        "\n",
        "print(len(flat_words)*.67) #198602\n",
        "\n",
        "#training data\n",
        "train_words = flat_words[:198602]\n",
        "train_pos = flat_pos[:198602]\n",
        "train_features = flat_features[:198602]\n",
        "\n",
        "#test data\n",
        "test_words = flat_words[198602:]\n",
        "test_pos = flat_pos[198602:]\n",
        "test_features = flat_features[198602:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198602.74000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmQ8jhnihyJ"
      },
      "source": [
        "**[Step 5]** Use scikit-learn for POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbxkJxZjEdr",
        "outputId": "42606d5b-b2c3-4013-81cf-4c632c5c6b1d"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse = True)\n",
        "\n",
        "train_features_vec = vec.fit_transform(train_features) #.fit: train\n",
        "\n",
        "test_features_vec = vec.transform(test_features)\n",
        "\n",
        "def pos_cats(pos_list):\n",
        "\tcat_d = {}\n",
        "\tfor idx, x in enumerate(list(set(pos_list))):\n",
        "\t\tcat_d[x] = idx\n",
        "\treturn(cat_d)\n",
        "\n",
        "def convert_pos(pos_list,pos_d):\n",
        "\tconverted = []\n",
        "\tfor x in pos_list:\n",
        "\t\tconverted.append(pos_d[x])\n",
        "\treturn(converted)\n",
        "\n",
        "def extract_pred_pos(pred_array,rev_d):\n",
        "  predicted = []\n",
        "  for x in pred_array:\n",
        "    predicted.append(rev_d[x])\n",
        "  return (predicted)\n",
        "\n",
        "pos_d = pos_cats(flat_pos) #create pos to number dictionary\n",
        "rev_pos_d = {value: key for (key, value) in pos_d.items()} #create number to POS dictionary for decoding output\n",
        "train_pos_num = convert_pos(train_pos,pos_d) #convert training pos tags to numbers\n",
        "\n",
        "print(pos_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'PUNCT': 0, 'NOUN': 1, 'CCONJ': 2, 'ADV': 3, 'PRON': 4, 'NUM': 5, 'INTJ': 6, 'VERB': 7, 'PART': 8, 'ADP': 9, 'AUX': 10, 'SYM': 11, 'X': 12, 'PROPN': 13, 'DET': 14, 'SCONJ': 15, 'ADJ': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA969t63jZdr",
        "outputId": "0e9ceb17-75c0-442f-c940-366c72f16d66"
      },
      "source": [
        "train_pos_num[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 3, 3, 15, 14, 1, 7, 1, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8kkO9gRjeBk"
      },
      "source": [
        "from sklearn import tree \n",
        "\n",
        "clf = tree.DecisionTreeClassifier() \n",
        "clf = clf.fit(train_features_vec,train_pos_num) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbXKxOo5pIr"
      },
      "source": [
        "**[Step 6]** Simple and Refined Accuracy\n",
        "\n",
        "With the model above, now we will\n",
        "\n",
        "(1) test its overall accuracy\n",
        "(2) its by-tag accuracy\n",
        "(3) try some test sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHZLOVkjrBx"
      },
      "source": [
        "# accuracy\n",
        "def pred_accuracy(pred,gold):\n",
        "\tc = 0\n",
        "\tf = 0\n",
        "\n",
        "\tfor idx, x in enumerate(pred):\n",
        "\t\t#print(x,gold[idx][\"pos\"])\n",
        "\t\tif x == gold[idx]:\n",
        "\t\t\tc+=1\n",
        "\t\telse:\n",
        "\t\t\tf+=1\n",
        "\treturn(c/(c+f))\n",
        "\n",
        "def prec_rec(accuracy_dict):\n",
        "\taccuracy_dict[\"TC\"] = accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"]\n",
        "\tif accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"] == 0:\n",
        "\t\taccuracy_dict[\"recall\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"recall\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] + accuracy_dict[\"FN\"])\n",
        "\n",
        "\tif accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"] == 0:\n",
        "\t\taccuracy_dict[\"precision\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"precision\"] = accuracy_dict[\"TP\"]/(accuracy_dict[\"TP\"] +accuracy_dict[\"FP\"])\n",
        "\tif accuracy_dict[\"precision\"] == 0 and accuracy_dict[\"recall\"] == 0:\n",
        "\t\taccuracy_dict[\"f1\"] = 0\n",
        "\telse:\n",
        "\t\taccuracy_dict[\"f1\"] = 2 * ((accuracy_dict[\"precision\"] * accuracy_dict[\"recall\"])/(accuracy_dict[\"precision\"] + accuracy_dict[\"recall\"]))\n",
        "\n",
        "\n",
        "def tag_prec_rec_flat(tested,gold):\n",
        "\ttag_d = {}\n",
        "\n",
        "\tfor idx, item in enumerate(gold):\n",
        "\t\t### convert formats, as needed: ###\n",
        "\t\tif type(item) == str:\n",
        "\t\t\titem = {\"pos\" : item}\n",
        "\n",
        "\t\tif type(tested[idx]) == str:\n",
        "\t\t\ttested[idx] = {\"pos\" : tested[idx]}\n",
        "\n",
        "\t\t### update tag dictionary as needed ###\n",
        "\t\tif item[\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[item[\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\t\tif tested[idx][\"pos\"] not in tag_d:\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]] = {\"TP\":0,\"FP\":0,\"FN\":0}\n",
        "\n",
        "\t\t### tabulate accuracy ###\n",
        "\t\tif item[\"pos\"] == tested[idx][\"pos\"]:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"TP\"] += 1\n",
        "\t\telse:\n",
        "\t\t\ttag_d[item[\"pos\"]][\"FN\"] += 1\n",
        "\t\t\ttag_d[tested[idx][\"pos\"]][\"FP\"] += 1\n",
        "\n",
        "\tfor x in tag_d:\n",
        "\t\tprec_rec(tag_d[x])\n",
        "\n",
        "\treturn(tag_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M35j0naZjmVc",
        "outputId": "5832f5b5-e849-4065-ff56-82bc5e224581"
      },
      "source": [
        "clf_pred = clf.predict(test_features_vec)\n",
        "# process train data and convert it from numbers to POS tags\n",
        "clf_pred_pos = extract_pred_pos(clf_pred, rev_pos_d)\n",
        "clf_pred_pos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'VERB', 'ADV', 'PUNCT', 'VERB', 'NOUN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMpbCqIxAGQa",
        "outputId": "479eb54c-f3a0-4a1b-f2d0-949c95817a7e"
      },
      "source": [
        "# check simple accuracy\n",
        "pred_accuracy(clf_pred_pos,test_pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.806675526477203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0N_2n7oAL_4"
      },
      "source": [
        "# [Q1]\n",
        "check by-tag accuracy \n",
        "\n",
        "pred_by_tag_accuracy = tag_prec_rec_flat(clf_pred_pos, test_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fg7uTUAtuo",
        "outputId": "b762aa3b-3386-4406-ddcf-686d97c803ca"
      },
      "source": [
        "# [Q2]\n",
        "#sort data by frequency (\"TC\")\n",
        "from operator import *\n",
        "pred_by_tag_accuracy_sorted = sorted(pred_by_tag_accuracy.items(),key=lambda x:getitem(x[1],'TC'), reverse = True)\n",
        "\n",
        "#output F1 score of top ten most frequent tags\n",
        "for x in pred_by_tag_accuracy_sorted[:10]:\n",
        "\tprint(x[0], x[1][\"f1\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOUN 0.7851822593386752\n",
            "VERB 0.7785680735422398\n",
            "ADV 0.8461856010568032\n",
            "PUNCT 0.9977424513216065\n",
            "CCONJ 0.7734303912647861\n",
            "SCONJ 0.8066155010269159\n",
            "ADJ 0.8407317729351627\n",
            "PROPN 0.32285276073619634\n",
            "AUX 0.8254954155575274\n",
            "PRON 0.8463652260804396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVL8T_VNDVOn"
      },
      "source": [
        "''' \n",
        "Try a few test cases to see how our tagger does on particular words in particular contexts\n",
        "'''\n",
        "\n",
        "def tagger(model,vec,rev_dict,extractor,token_list):\n",
        "\ttagged = [] #for final word + tag output\n",
        "\n",
        "\tfor sent in token_list:\n",
        "\t\tfeatures = [] #in progress tagging list\n",
        "\t\ttagging = [] #final word-tag pairs\n",
        "\n",
        "\t\tfor idx, token in enumerate(sent):\n",
        "\t\t\tfeatures.append({\"word\" : token}) # add word to feature set\n",
        "\t\t\t#print(features,idx,features[idx])\n",
        "\t\t\tfeatures[idx] = extractor(features,idx,features[idx]) #add featured token to features list\n",
        "\t\t\t#print(features)\n",
        "\t\t\t#print(vec.transform(features[idx]))\n",
        "\t\t\t#print(model.predict(vec.transform([features[idx]])))\n",
        "\t\t\tfeatures[idx][\"pos\"] = rev_dict[model.predict(vec.transform([features[idx]]))[0]] #add pos to features - this happens one token at a time\n",
        "\t\t\ttagging.append({\"word\" : token, \"pos\" : features[idx][\"pos\"]}) #add word-tag pairs to sentence level output\n",
        "\t\ttagged.append(tagging) #add sentence to output\n",
        "\n",
        "\treturn(tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xR7Ed65EmZN",
        "outputId": "8c41cf25-c98e-42d8-96c4-04a20f8027f2"
      },
      "source": [
        "# [Q3]\n",
        "\n",
        "sample1 = [\"아빠가 방으로 들어가셨다.\"]\n",
        "print(tagger(clf, vec, rev_pos_d, simple_features, sample1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[{'word': '아', 'pos': 'INTJ'}, {'word': '빠', 'pos': 'NOUN'}, {'word': '가', 'pos': 'NOUN'}, {'word': ' ', 'pos': 'NOUN'}, {'word': '방', 'pos': 'NOUN'}, {'word': '으', 'pos': 'NOUN'}, {'word': '로', 'pos': 'NOUN'}, {'word': ' ', 'pos': 'NOUN'}, {'word': '들', 'pos': 'VERB'}, {'word': '어', 'pos': 'NOUN'}, {'word': '가', 'pos': 'NOUN'}, {'word': '셨', 'pos': 'NOUN'}, {'word': '다', 'pos': 'ADV'}, {'word': '.', 'pos': 'PUNCT'}]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}